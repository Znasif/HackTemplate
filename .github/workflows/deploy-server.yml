name: Deploy GPU Server to AWS

on:
  push:
    branches: [ main, master ]
    paths:
      - 'processors/**'
      - 'audio_processors/**'
      - 'stream*.py'
      - 'processor_config.json'
      - 'Dockerfile'
      - 'requirements/**'
      - '.github/workflows/deploy-server.yml'
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Force deployment even without changes'
        required: false
        default: 'false'

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: whatsai-gpu-server

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: false  # We'll handle large files separately
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          platforms: linux/amd64
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Extract requirements from conda environments (if available)
        run: |
          # Create requirements directory if it doesn't exist
          mkdir -p requirements
          
          # Create base requirements file
          cat > requirements/base-requirements.txt << 'EOF'
          fastapi==0.104.1
          uvicorn[standard]==0.24.0
          websockets==12.0
          opencv-python-headless==4.8.1.78
          pillow==10.1.0
          numpy==1.24.3
          torch==2.1.0
          torchvision==0.16.0
          transformers==4.35.2
          accelerate==0.24.1
          httpx==0.25.2
          python-dotenv==1.0.0
          pydantic==2.5.0
          starlette==0.27.0
          soundfile==0.12.1
          librosa==0.10.1
          mediapipe==0.10.7
          ultralytics==8.0.205
          open3d==0.18.0
          scipy==1.11.4
          scikit-learn==1.3.2
          matplotlib==3.8.2
          boto3==1.34.0
          asyncio-mqtt==0.15.0
          depth-pro
          groq
          openai
          google-generativeai
          EOF
          
          echo "Created base requirements file"
      
      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # Build and push Docker image
          docker buildx build \
            --platform linux/amd64 \
            --push \
            --tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            --tag $ECR_REGISTRY/$ECR_REPOSITORY:latest \
            --cache-from type=gha \
            --cache-to type=gha,mode=max \
            .
          
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT
      
      - name: Create EC2 deployment script
        run: |
          cat > deploy-ec2.sh << 'EOF'
          #!/bin/bash
          set -e
          
          # Configuration
          INSTANCE_NAME="whatsai-gpu-server"
          INSTANCE_TYPE="g4dn.xlarge"  # GPU instance type
          KEY_NAME="${{ secrets.EC2_KEY_NAME }}"
          SECURITY_GROUP="${{ secrets.EC2_SECURITY_GROUP }}"
          SUBNET_ID="${{ secrets.EC2_SUBNET_ID }}"
          
          # Deep Learning AMI (Ubuntu 22.04) - Update this ID for your region
          AMI_ID="ami-0c02fb55956c7d316"  # Deep Learning AMI GPU PyTorch 2.0.1 (Ubuntu 22.04)
          
          ECR_IMAGE="${{ steps.build-image.outputs.image }}"
          
          # User data script for EC2 instance
          cat > user-data.sh << 'USERDATA'
          #!/bin/bash
          exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1
          
          # Update system
          apt-get update -y
          
          # Install Docker if not present
          if ! command -v docker &> /dev/null; then
              curl -fsSL https://get.docker.com | sh
              usermod -aG docker ubuntu
              systemctl enable docker
              systemctl start docker
          fi
          
          # Install nvidia-container-toolkit
          distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
          curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add -
          curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list
          apt-get update && apt-get install -y nvidia-container-toolkit
          systemctl restart docker
          
          # Login to ECR
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin ${{ steps.login-ecr.outputs.registry }}
          
          # Pull and run the container
          docker stop whatsai-server || true
          docker rm whatsai-server || true
          
          # Create environment file
          cat > /home/ubuntu/.env << 'ENVEOF'
          PORT=8080
          GROQ_API_KEY=${{ secrets.GROQ_API_KEY }}
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}
          MONITOR=1
          ENVEOF
          
          # Run container with GPU support
          docker run -d \
            --name whatsai-server \
            --gpus all \
            --restart unless-stopped \
            -p 8080:8080 \
            --env-file /home/ubuntu/.env \
            -v /home/ubuntu/models:/app/models \
            $ECR_IMAGE
          
          echo "Container started successfully"
          
          USERDATA
          
          # Check if instance already exists
          EXISTING_INSTANCE=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=$INSTANCE_NAME" "Name=instance-state-name,Values=running,pending,stopping,stopped" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text)
          
          if [ "$EXISTING_INSTANCE" != "None" ] && [ "$EXISTING_INSTANCE" != "" ]; then
              echo "Existing instance found: $EXISTING_INSTANCE"
              echo "Stopping existing instance..."
              aws ec2 terminate-instances --instance-ids $EXISTING_INSTANCE
              
              echo "Waiting for instance to terminate..."
              aws ec2 wait instance-terminated --instance-ids $EXISTING_INSTANCE
          fi
          
          # Launch new spot instance
          echo "Launching new GPU spot instance..."
          
          SPOT_REQUEST=$(aws ec2 request-spot-instances \
            --spot-price "0.50" \
            --instance-count 1 \
            --type "one-time" \
            --launch-specification '{
              "ImageId": "'$AMI_ID'",
              "InstanceType": "'$INSTANCE_TYPE'",
              "KeyName": "'$KEY_NAME'",
              "SecurityGroupIds": ["'$SECURITY_GROUP'"],
              "SubnetId": "'$SUBNET_ID'",
              "UserData": "'$(base64 -w 0 user-data.sh)'",
              "IamInstanceProfile": {
                "Name": "EC2ECRRole"
              },
              "BlockDeviceMappings": [
                {
                  "DeviceName": "/dev/sda1",
                  "Ebs": {
                    "VolumeSize": 100,
                    "VolumeType": "gp3",
                    "DeleteOnTermination": true
                  }
                }
              ]
            }' \
            --query 'SpotInstanceRequests[0].SpotInstanceRequestId' \
            --output text)
          
          echo "Spot request created: $SPOT_REQUEST"
          
          # Wait for spot request to be fulfilled
          echo "Waiting for spot request to be fulfilled..."
          aws ec2 wait spot-instance-request-fulfilled --spot-instance-request-ids $SPOT_REQUEST
          
          # Get instance ID
          INSTANCE_ID=$(aws ec2 describe-spot-instance-requests \
            --spot-instance-request-ids $SPOT_REQUEST \
            --query 'SpotInstanceRequests[0].InstanceId' \
            --output text)
          
          echo "Instance ID: $INSTANCE_ID"
          
          # Tag the instance
          aws ec2 create-tags \
            --resources $INSTANCE_ID \
            --tags Key=Name,Value=$INSTANCE_NAME Key=Environment,Value=production
          
          # Wait for instance to be running
          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running --instance-ids $INSTANCE_ID
          
          # Get public IP
          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids $INSTANCE_ID \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)
          
          echo "Instance launched successfully!"
          echo "Instance ID: $INSTANCE_ID"
          echo "Public IP: $PUBLIC_IP"
          echo "You can access the server at: http://$PUBLIC_IP:8080"
          echo "SSH command: ssh -i ~/.ssh/$KEY_NAME.pem ubuntu@$PUBLIC_IP"
          
          EOF
          
          chmod +x deploy-ec2.sh
      
      - name: Deploy to EC2 (if enabled)
        if: github.ref == 'refs/heads/main' || github.event.inputs.force_deploy == 'true'
        run: |
          # Only deploy if we have the necessary secrets
          if [ -n "${{ secrets.EC2_KEY_NAME }}" ]; then
            echo "Deploying to EC2..."
            ./deploy-ec2.sh
          else
            echo "EC2 deployment skipped - missing required secrets"
            echo "Set the following secrets to enable EC2 deployment:"
            echo "- EC2_KEY_NAME"
            echo "- EC2_SECURITY_GROUP" 
            echo "- EC2_SUBNET_ID"
          fi
      
      - name: Output deployment info
        run: |
          echo "## Deployment Complete! ðŸš€" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ECR Image:** \`${{ steps.build-image.outputs.image }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Manual EC2 Deployment" >> $GITHUB_STEP_SUMMARY
          echo "If automatic deployment was skipped, you can deploy manually:" >> $GITHUB_STEP_SUMMARY
          echo '```bash' >> $GITHUB_STEP_SUMMARY
          echo 'aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin ${{ steps.login-ecr.outputs.registry }}' >> $GITHUB_STEP_SUMMARY
          echo 'docker pull ${{ steps.build-image.outputs.image }}' >> $GITHUB_STEP_SUMMARY
          echo 'docker run -d --name whatsai-server --gpus all -p 8080:8080 --env-file .env ${{ steps.build-image.outputs.image }}' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY